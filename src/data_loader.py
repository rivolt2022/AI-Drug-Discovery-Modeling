"""
ëª¨ë¸ í•™ìŠµì„ ìœ„í•œ ë°ì´í„° ë¡œë”© ëª¨ë“ˆ

ì´ ëª¨ë“ˆì€ read_excel.pyì™€ read_csv.pyì˜ í•¨ìˆ˜ë“¤ì„ í™œìš©í•˜ì—¬
ëª¨ë¸ í•™ìŠµì— í•„ìš”í•œ ì •ì œëœ ë°ì´í„°ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
"""

import pandas as pd
import numpy as np
import os
import sys

# ìƒìœ„ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from data.preprocessing.read_excel import read_cas_excel, read_ligand_smiles_sheet, read_ic50_sheet
from data.preprocessing.read_csv import read_test_csv, read_chembl_csv, get_clean_training_data

class DrugDiscoveryDataLoader:
    """AI ì‹ ì•½ê°œë°œ ëª¨ë¸ë§ì„ ìœ„í•œ ë°ì´í„° ë¡œë” í´ë˜ìŠ¤"""
    
    def __init__(self, data_dir='data'):
        """
        ë°ì´í„° ë¡œë” ì´ˆê¸°í™”
        
        Args:
            data_dir (str): ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ
        """
        self.data_dir = data_dir
        self.cache = {}  # ë°ì´í„° ìºì‹±ì„ ìœ„í•œ ë”•ì…”ë„ˆë¦¬
        
    def load_test_data(self, use_cache=True):
        """
        í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
        
        Args:
            use_cache (bool): ìºì‹œëœ ë°ì´í„° ì‚¬ìš© ì—¬ë¶€
            
        Returns:
            pd.DataFrame: í…ŒìŠ¤íŠ¸ ë°ì´í„° (ID, SMILES)
        """
        if use_cache and 'test_data' in self.cache:
            print("ğŸ“‹ ìºì‹œëœ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì‚¬ìš©")
            return self.cache['test_data']
        
        print("ï¿½ï¿½ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë”© ì¤‘...")
        test_df = read_test_csv()
        
        if test_df is not None:
            # ì»¬ëŸ¼ëª… ì •ê·œí™” (Smiles -> SMILES)
            if 'Smiles' in test_df.columns:
                test_df = test_df.rename(columns={'Smiles': 'SMILES'})
            
            # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
            required_cols = ['ID', 'SMILES']
            available_cols = [col for col in required_cols if col in test_df.columns]
            
            if len(available_cols) == 2:
                test_df = test_df[available_cols]
                print(f"âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(test_df)}ê°œ í™”í•©ë¬¼")
                self.cache['test_data'] = test_df
                return test_df
            else:
                print(f"âŒ í•„ìš”í•œ ì»¬ëŸ¼ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥: {available_cols}")
                return None
        else:
            print("âŒ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
            return None
    
    def load_training_data_from_chembl(self, use_cache=True):
        """
        ChEMBL ë°ì´í„°ì—ì„œ í›ˆë ¨ ë°ì´í„° ë¡œë“œ
        
        Args:
            use_cache (bool): ìºì‹œëœ ë°ì´í„° ì‚¬ìš© ì—¬ë¶€
            
        Returns:
            pd.DataFrame: í›ˆë ¨ ë°ì´í„° (SMILES, IC50_nM, pIC50)
        """
        if use_cache and 'training_data_chembl' in self.cache:
            print("ğŸ“‹ ìºì‹œëœ ChEMBL í›ˆë ¨ ë°ì´í„° ì‚¬ìš©")
            return self.cache['training_data_chembl']
        
        print("ï¿½ï¿½ ChEMBL í›ˆë ¨ ë°ì´í„° ë¡œë”© ì¤‘...")
        training_df = get_clean_training_data()
        
        if training_df is not None:
            # ì»¬ëŸ¼ëª… ì •ê·œí™”
            if 'Smiles' in training_df.columns:
                training_df = training_df.rename(columns={'Smiles': 'SMILES'})
            
            # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
            required_cols = ['SMILES', 'IC50_nM', 'pIC50']
            available_cols = [col for col in required_cols if col in training_df.columns]
            
            if len(available_cols) >= 2:
                training_df = training_df[available_cols]
                print(f"âœ… ChEMBL í›ˆë ¨ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(training_df)}ê°œ í™”í•©ë¬¼")
                self.cache['training_data_chembl'] = training_df
                return training_df
            else:
                print(f"âŒ í•„ìš”í•œ ì»¬ëŸ¼ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥: {available_cols}")
                return None
        else:
            print("âŒ ChEMBL í›ˆë ¨ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
            return None
    
    def load_training_data_from_cas(self, use_cache=True):
        """
        CAS ì—‘ì…€ ë°ì´í„°ì—ì„œ í›ˆë ¨ ë°ì´í„° ë¡œë“œ
        
        Args:
            use_cache (bool): ìºì‹œëœ ë°ì´í„° ì‚¬ìš© ì—¬ë¶€
            
        Returns:
            pd.DataFrame: í›ˆë ¨ ë°ì´í„° (SMILES, IC50_nM, pIC50)
        """
        if use_cache and 'training_data_cas' in self.cache:
            print("ğŸ“‹ ìºì‹œëœ CAS í›ˆë ¨ ë°ì´í„° ì‚¬ìš©")
            return self.cache['training_data_cas']
        
        print("ï¿½ï¿½ CAS í›ˆë ¨ ë°ì´í„° ë¡œë”© ì¤‘...")
        
        try:
            # CAS ì—‘ì…€ íŒŒì¼ ì½ê¸°
            cas_df = read_cas_excel()
            
            if cas_df is None:
                print("âŒ CAS ì—‘ì…€ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨")
                return None
            
            # SMILESì™€ IC50 ê´€ë ¨ ì»¬ëŸ¼ ì°¾ê¸°
            smiles_col = None
            ic50_col = None
            
            for col in cas_df.columns:
                col_lower = str(col).lower()
                if 'smiles' in col_lower:
                    smiles_col = col
                if 'ic50' in col_lower or 'activity' in col_lower:
                    ic50_col = col
            
            if smiles_col is None or ic50_col is None:
                print(f"âŒ SMILES ë˜ëŠ” IC50 ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                print(f"   ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {list(cas_df.columns)}")
                return None
            
            # ë°ì´í„° ì •ì œ
            training_df = cas_df[[smiles_col, ic50_col]].copy()
            training_df = training_df.rename(columns={smiles_col: 'SMILES', ic50_col: 'IC50_raw'})
            
            # ê²°ì¸¡ì¹˜ ì œê±°
            training_df = training_df.dropna()
            
            # IC50 ê°’ì„ ìˆ˜ì¹˜í˜•ìœ¼ë¡œ ë³€í™˜
            training_df['IC50_nM'] = pd.to_numeric(training_df['IC50_raw'], errors='coerce')
            training_df = training_df.dropna(subset=['IC50_nM'])
            
            # pIC50 ê³„ì‚°
            training_df['pIC50'] = -np.log10(training_df['IC50_nM'] * 1e-9)
            
            # ìµœì¢… ì»¬ëŸ¼ë§Œ ì„ íƒ
            final_df = training_df[['SMILES', 'IC50_nM', 'pIC50']].copy()
            
            print(f"âœ… CAS í›ˆë ¨ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(final_df)}ê°œ í™”í•©ë¬¼")
            self.cache['training_data_cas'] = final_df
            return final_df
            
        except Exception as e:
            print(f"âŒ CAS ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
            return None
    
    def load_combined_training_data(self, use_cache=True):
        """
        ëª¨ë“  ì†ŒìŠ¤ì˜ í›ˆë ¨ ë°ì´í„°ë¥¼ ê²°í•©í•˜ì—¬ ë¡œë“œ
        
        Args:
            use_cache (bool): ìºì‹œëœ ë°ì´í„° ì‚¬ìš© ì—¬ë¶€
            
        Returns:
            pd.DataFrame: ê²°í•©ëœ í›ˆë ¨ ë°ì´í„°
        """
        if use_cache and 'combined_training_data' in self.cache:
            print("ğŸ“‹ ìºì‹œëœ ê²°í•© í›ˆë ¨ ë°ì´í„° ì‚¬ìš©")
            return self.cache['combined_training_data']
        
        print("ğŸ“‹ ê²°í•© í›ˆë ¨ ë°ì´í„° ë¡œë”© ì¤‘...")
        
        # ê° ì†ŒìŠ¤ì—ì„œ ë°ì´í„° ë¡œë“œ
        datasets = []
        
        # ChEMBL ë°ì´í„°
        chembl_data = self.load_training_data_from_chembl(use_cache=False)
        if chembl_data is not None:
            chembl_data['source'] = 'ChEMBL'
            datasets.append(chembl_data)
            print(f"  - ChEMBL: {len(chembl_data)}ê°œ í™”í•©ë¬¼")
        
        # CAS ë°ì´í„°
        cas_data = self.load_training_data_from_cas(use_cache=False)
        if cas_data is not None:
            cas_data['source'] = 'CAS'
            datasets.append(cas_data)
            print(f"  - CAS: {len(cas_data)}ê°œ í™”í•©ë¬¼")
        
        if not datasets:
            print("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ í›ˆë ¨ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # ë°ì´í„° ê²°í•©
        combined_df = pd.concat(datasets, ignore_index=True)
        
        # ì¤‘ë³µ SMILES ì œê±° (ê°€ì¥ ë†’ì€ pIC50 ê°’ ìœ ì§€)
        combined_df = combined_df.sort_values('pIC50', ascending=False)
        combined_df = combined_df.drop_duplicates(subset=['SMILES'], keep='first')
        
        print(f"âœ… ê²°í•© í›ˆë ¨ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(combined_df)}ê°œ í™”í•©ë¬¼")
        print(f"   - ì¤‘ë³µ ì œê±° í›„: {len(combined_df)}ê°œ í™”í•©ë¬¼")
        
        self.cache['combined_training_data'] = combined_df
        return combined_df
    
    def get_data_summary(self):
        """
        ë°ì´í„° ìš”ì•½ ì •ë³´ ë°˜í™˜
        
        Returns:
            dict: ë°ì´í„° ìš”ì•½ ì •ë³´
        """
        summary = {}
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìš”ì•½
        test_data = self.load_test_data()
        if test_data is not None:
            summary['test'] = {
                'count': len(test_data),
                'columns': list(test_data.columns)
            }
        
        # í›ˆë ¨ ë°ì´í„° ìš”ì•½
        training_data = self.load_combined_training_data()
        if training_data is not None:
            summary['training'] = {
                'count': len(training_data),
                'columns': list(training_data.columns),
                'pIC50_stats': {
                    'min': training_data['pIC50'].min(),
                    'max': training_data['pIC50'].max(),
                    'mean': training_data['pIC50'].mean(),
                    'median': training_data['pIC50'].median()
                },
                'source_distribution': training_data['source'].value_counts().to_dict()
            }
        
        return summary
    
    def validate_smiles(self, df, smiles_col='SMILES'):
        """
        SMILES ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬
        
        Args:
            df (pd.DataFrame): ê²€ì‚¬í•  ë°ì´í„°í”„ë ˆì„
            smiles_col (str): SMILES ì»¬ëŸ¼ëª…
            
        Returns:
            pd.DataFrame: ìœ íš¨í•œ SMILESë§Œ í¬í•¨ëœ ë°ì´í„°í”„ë ˆì„
        """
        if smiles_col not in df.columns:
            print(f"âŒ {smiles_col} ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return df
        
        original_count = len(df)
        
        # ë¹ˆ ë¬¸ìì—´ ì œê±°
        df = df[df[smiles_col].str.strip() != '']
        
        # None/NaN ê°’ ì œê±°
        df = df.dropna(subset=[smiles_col])
        
        # ìµœì†Œ ê¸¸ì´ ê²€ì‚¬ (SMILESëŠ” ë³´í†µ 5ì ì´ìƒ)
        df = df[df[smiles_col].str.len() >= 5]
        
        # ê¸°ë³¸ì ì¸ SMILES íŒ¨í„´ ê²€ì‚¬ (ì›ì ê¸°í˜¸ í¬í•¨)
        valid_atoms = df[smiles_col].str.contains(r'[COHNSFPClBrI]', regex=True)
        df = df[valid_atoms]
        
        # ë¶„ì êµ¬ì¡° ê¸°í˜¸ í¬í•¨ ê²€ì‚¬ (ê´„í˜¸, ê²°í•© ê¸°í˜¸, ìˆ«ì)
        valid_structure = df[smiles_col].str.contains(r'[()=#123456789]', regex=True)
        df = df[valid_structure]
        
        final_count = len(df)
        removed_count = original_count - final_count
        
        if removed_count > 0:
            print(f"âš ï¸ SMILES ê²€ì¦: {removed_count}ê°œ ìœ íš¨í•˜ì§€ ì•Šì€ SMILES ì œê±°")
            print(f"   - ì›ë³¸: {original_count}ê°œ â†’ ê²€ì¦ í›„: {final_count}ê°œ")
        
        return df

    def prepare_model_data(self, test_size=0.2, random_state=42):
        """
        ëª¨ë¸ í•™ìŠµì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„
        
        Args:
            test_size (float): í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ë¹„ìœ¨
            random_state (int): ëœë¤ ì‹œë“œ
            
        Returns:
            dict: ëª¨ë¸ í•™ìŠµìš© ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        """
        print(" ëª¨ë¸ í•™ìŠµìš© ë°ì´í„° ì¤€ë¹„ ì¤‘...")
        
        # í›ˆë ¨ ë°ì´í„° ë¡œë“œ
        training_data = self.load_combined_training_data()
        if training_data is None:
            print("âŒ í›ˆë ¨ ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # SMILES ìœ íš¨ì„± ê²€ì‚¬
        training_data = self.validate_smiles(training_data)
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
        test_data = self.load_test_data()
        if test_data is None:
            print("âŒ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # SMILES ìœ íš¨ì„± ê²€ì‚¬
        test_data = self.validate_smiles(test_data)
        
        # í›ˆë ¨/ê²€ì¦ ë°ì´í„° ë¶„í• 
        from sklearn.model_selection import train_test_split
        
        train_df, val_df = train_test_split(
            training_data, 
            test_size=test_size, 
            random_state=random_state,
            stratify=None  # pIC50 ê°’ì´ ì—°ì†í˜•ì´ë¯€ë¡œ stratify ì‚¬ìš© ë¶ˆê°€
        )
        
        # ê²°ê³¼ ë°ì´í„° êµ¬ì„±
        model_data = {
            'train': train_df,
            'validation': val_df,
            'test': test_data,
            'full_training': training_data
        }
        
        print(f"âœ… ëª¨ë¸ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ:")
        print(f"   - í›ˆë ¨ ì„¸íŠ¸: {len(train_df)}ê°œ í™”í•©ë¬¼")
        print(f"   - ê²€ì¦ ì„¸íŠ¸: {len(val_df)}ê°œ í™”í•©ë¬¼")
        print(f"   - í…ŒìŠ¤íŠ¸ ì„¸íŠ¸: {len(test_data)}ê°œ í™”í•©ë¬¼")
        print(f"   - ì „ì²´ í›ˆë ¨ ë°ì´í„°: {len(training_data)}ê°œ í™”í•©ë¬¼")
        
        return model_data

def create_data_loader(data_dir='data'):
    """
    ë°ì´í„° ë¡œë” ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    
    Args:
        data_dir (str): ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ
        
    Returns:
        DrugDiscoveryDataLoader: ë°ì´í„° ë¡œë” ì¸ìŠ¤í„´ìŠ¤
    """
    return DrugDiscoveryDataLoader(data_dir)

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ë°ì´í„° ë¡œë” ìƒì„±
    loader = create_data_loader()
    
    # ë°ì´í„° ìš”ì•½ ì¶œë ¥
    summary = loader.get_data_summary()
    print("\nğŸ“Š ë°ì´í„° ìš”ì•½:")
    for key, value in summary.items():
        print(f"  {key}: {value}")
    
    # ëª¨ë¸ ë°ì´í„° ì¤€ë¹„
    model_data = loader.prepare_model_data()
    
    if model_data:
        print("\nâœ… ëª¨ë¸ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ!")
        print("ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°:")
        for key, df in model_data.items():
            print(f"  - {key}: {len(df)}ê°œ í™”í•©ë¬¼")
    else:
        print("\nâŒ ëª¨ë¸ ë°ì´í„° ì¤€ë¹„ ì‹¤íŒ¨")